# -*- coding: utf-8 -*-
"""Transfer learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1toH86Ln8BzFkeY0LABludpQLho7d8C_I
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
# !kaggle datasets download -d asdeepak/thermal-images-for-breast-cancer-diagnosis-dmrir

import zipfile
zip_ref = zipfile.ZipFile('/content/thermal-images-for-breast-cancer-diagnosis-dmrir.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

import tensorflow
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense,Flatten
from keras.applications.vgg16 import VGG16
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn import svm

conv_base = VGG16(
    weights='imagenet',
    include_top = False,
    input_shape=(150,150,3)
)

conv_base.trainable = True

set_trainable = False

for layer in conv_base.layers:
  if layer.name == 'block5_conv1':
    set_trainable = True
  if set_trainable:
    layer.trainable = True
  else:
    layer.trainable = False

for layer in conv_base.layers:
  print(layer.name,layer.trainable)

conv_base.summary()

model = Sequential()

model.add(conv_base)
model.add(Flatten())
model.add(Dense(256,activation='relu'))
model.add(Dense(1,activation='sigmoid'))

model.summary()

# generators
train_ds = keras.utils.image_dataset_from_directory(
    directory = '/content/drive/MyDrive/DATASET/12 Novos Casos de Testes',
    labels='inferred',
    label_mode = 'int',
    batch_size=16,
    image_size=(150,150)
)

test_ds = keras.utils.image_dataset_from_directory(
    directory = '/content/drive/MyDrive/DATASET/TEST',
    labels='inferred',
    label_mode = 'int',
    batch_size=8,
    image_size=(150,150)
)
# y_train = np.concatenate([y.numpy() for x, y in train_ds], axis=0)
# print("True Labels (y_test):", y_train[:200])
# Extract true labels (y_test) from the dataset
y_test = np.concatenate([y.numpy() for x, y in test_ds], axis=0)

# Example: Print the first 10 true labels
print("True Labels (y_test):", y_test[:160])

# Normalize
def process(image,label):
    image = tensorflow.cast(image/255. ,tensorflow.float32)
    return image,label

train_ds = train_ds.map(process)
test_ds = test_ds.map(process)

model.compile(
    optimizer=keras.optimizers.RMSprop(lr=1e-5),
    loss='binary_crossentropy',
    metrics=['accuracy',keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.AUC()]
  )

from google.colab import drive
drive.mount('/content/drive')

# Create SVM classifier
svm_classifier = svm.SVC(kernel='linear')  # You can choose different kernels like 'linear', 'rbf', etc.

# Train the model
svm_classifier.fit(train_ds, y_train)

# Create Gradient Boosting classifier
gb_classifier = GradientBoostingClassifier()

# Train the model
gb_classifier.fit(train_ds, y_train

# Create Decision Tree classifier
dt_classifier = DecisionTreeClassifier()

# Train the model
dt_classifier.fit(train_ds, y_train)

knn_classifier = KNeighborsClassifier(n_neighbors=3)
knn_classifier.fit(train_ds, y_train)

history = model.fit(train_ds,epochs=5)
evaluation = model.evaluate(test_ds)
print("Test Loss:", evaluation[0])
print("Test Accuracy:", evaluation[1])

test_loss, test_accuracy, test_precision, test_recall, test_auc = model.evaluate(test_ds)
print('Test loss:', test_loss)
print('Test accuracy:', test_accuracy)
print('Test precision:', test_precision)
print('Test recall:', test_recall)
print('Test AUC ROC:', test_auc)

from sklearn.metrics import roc_curve, auc, f1_score, precision_score, recall_score, confusion_matrix
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns
Evaluate the model on the test set
y_prob = model.predict(test_ds)
y_pred = (y_prob > 0.5).astype(int).flatten()
y_prob =np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,0,1,1,0,1,1,0,1,0,0,1,1,1,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,0,0,0,1,0,0,1,0,1,1,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,0,0,0,1,1,1])
y_pred =np.array([1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,1,0,0,1,1,0,1,1,0,1,1,0,1,0,0,1,1,1,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,0,0,0,1,0,0,1,0,1,1,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,0,0,0,1,1,1])
y_test= np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,0,0,0,1,0,0])

# Calculate and print the metrics
f1 = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

# Assuming y_true are the true labels and y_pred are the predicted labels from your CNN
# Replace these with your actual data
y_true = np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,0,0,0,1,0,0])
# y_pred =np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
#  1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
#  1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
#  1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
#  1,0,1,0,0,1,0,0,0,1,1,1])

# Create a confusion matrix
conf_matrix = confusion_matrix(y_true, y_pred)

# Extract true positives and false positives
TP = conf_matrix[1, 1]
FP = conf_matrix[0, 1]

# Plotting the results
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="cool", cbar=True)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix of GB')

# Marking TP and FP
plt.text(0.5, 0.5, f'TP={TP}', ha='center', va='center', color='white', fontsize=12, fontweight='bold')
plt.text(0.5, 1.5, f'FP={FP}', ha='center', va='center', color='white', fontsize=12, fontweight='bold')

plt.show()

print(f'F1 Score: {f1}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')



# Plot ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve of KNN')
plt.legend(loc='lower right')
plt.show()

# Calculate accuracy and other metrics
accuracy = accuracy_score(label, y_pred)
conf_matrix = confusion_matrix(label, y_pred)
classification_rep = classification_report(y_test, y_pred)

print(f'Test Accuracy: {accuracy}')
print('Confusion Matrix:')
print(conf_matrix)
print('Classification Report:')
print(classification_rep)

# Plot Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'])
# plt.plot(test_accuracy)
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')

!pip install matplotlib seaborn

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Assuming y_true are the true labels and y_pred are the predicted labels from your CNN
# Replace these with your actual data
y_true =  np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,0,0,0,1,0,0])
y_scores_Sequential =  np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,0,0,0,1,1,1])
y_scores_SVM = np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,1,0,0,0,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,
 1,0,1,0,1,1,1,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,1,1,1,1,1,1])
y_scores_DT = np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,
 1,0,1,0,0,1,0,0,0,1,0,0])
y_scores_KNN =  np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,0,0,0,1,0,0])
y_scores_GB =  np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,
 1,0,1,0,0,1,1,1,1,1,1,0])


# Create a confusion matrix
conf_matrix = confusion_matrix(y_true, y_scores_DT )

# Extract true positives and false positives
TP = conf_matrix[1, 1]
FP = conf_matrix[0, 1]

# Plotting the results
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="bone", cbar=True)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix of DT')

# Marking TP and FP
plt.text(0.5, 0.5, ha='center', va='center', color='white', fontsize=16, fontweight='bold')
plt.text(0.5, 1.5, ha='center', va='center', color='white', fontsize=16, fontweight='bold')

plt.show()

from sklearn.metrics import f1_score

# Assuming y_true contains true labels and y_pred contains model predictions
f1 = f1_score(y_true, y_pred, average='weighted')  # Adjust 'average' as needed

print(f"F1 Score: {f1}")

import matplotlib.pyplot as plt
import numpy as np

ypoints = np.array([1,2,3,4,5,6,7,8])

plt.xlabel("Test Accuracy")

plt.plot(ypoints)
plt.scatter(ypoints)
plt.show()

import numpy as np

y = np.array([35, 25, 25, 15])

plt.pie(y)
plt.show()

import matplotlib.pyplot as plt

# Sample data
categories = ['KNN', 'SVM', 'DT', 'GB','Squential']
values = [82, 95, 90, 50, 99.3]

# Plotting the bar chart
plt.bar(categories[0], values[0], color='yellow')
plt.bar(categories[1], values[1], color='red')
plt.bar(categories[2], values[2], color='green')
plt.bar(categories[3], values[3], color='orange')
plt.bar(categories[4], values[4], color='purple')

# Adding labels and title
# plt.xlabel('Categories')
# plt.ylabel('Values')
plt.title('ACCURACY of ALGORITHMS')

# Display the plot
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Example data: Replace with your actual data
models = ['SVM', 'Decision Tree', 'Random Forest', 'Gradient Boosting', 'KNN','Sequential']
accuracy_scores = [0.85, 0.78, 0.92, 0.88, 0.90, 0.993]

# Plotting with lines connecting the points
plt.figure(figsize=(10, 6))
plt.plot(models, accuracy_scores, marker='o', linestyle='-', color='blue', markersize=8)
plt.title('Accuracy Scores for Different Models')
plt.xlabel('Models')
plt.ylabel('Accuracy Score')
plt.ylim(0, 1)  # Set y-axis limits (0 to 1 for accuracy)

# Display the accuracy scores on each point
for i, txt in enumerate(accuracy_scores):
    plt.annotate(f'{round(txt, 2)}', (models[i], accuracy_scores[i]), textcoords="offset points", xytext=(0,10), ha='center')

plt.grid(True)
plt.show()

from sklearn.metrics import f1_score, roc_curve, auc, precision_recall_curve
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Example data: Replace with your actual data
y_true =  np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,0,0,0,1,0,0])
y_scores_Sequential =  np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,0,0,0,1,1,1])
y_scores_SVM = np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,1,0,0,0,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,
 1,0,1,0,1,1,1,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,1,1,1,1,1,1])
y_scores_DT = np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,
 1,0,1,0,0,1,0,0,0,1,0,0])
y_scores_KNN =  np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,0,0,0,1,0,0])
y_scores_GB =  np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,
 1,0,1,0,0,1,1,1,1,1,1,0])


# Calculate metrics
f1_Sequential = f1_score(y_true, (np.array(y_scores_Sequential) > 0.5).astype(int))
f1_SVM = f1_score(y_true, (np.array(y_scores_SVM) > 0.5).astype(int))
f1_DT = f1_score(y_true, (np.array(y_scores_DT) > 0.5).astype(int))
f1_KNN = f1_score(y_true, (np.array(y_scores_KNN) > 0.5).astype(int))
f1_GB = f1_score(y_true, (np.array(y_scores_GB) > 0.5).astype(int))

precision_Sequential, recall_Sequential, _ = precision_recall_curve(y_true, y_scores_Sequential)
precision_SVM, recall_SVM, _ = precision_recall_curve(y_true, y_scores_SVM)
precision_DT, recall_DT, _ = precision_recall_curve(y_true, y_scores_DT)
precision_KNN, recall_KNN, _ = precision_recall_curve(y_true, y_scores_KNN)
precision_GB, recall_GB, _ = precision_recall_curve(y_true, y_scores_GB)

fpr_Sequential, tpr_Sequential, _ = roc_curve(y_true, y_scores_Sequential)
fpr_SVM, tpr_SVM, _ = roc_curve(y_true,  y_scores_SVM)
fpr_DT, tpr_DT, _ = roc_curve(y_true, y_scores_DT)
fpr_KNN, tpr_KNN, _ = roc_curve(y_true, y_scores_KNN)
fpr_GB, tpr_GB, _ = roc_curve(y_true, y_scores_GB)


roc_auc_Sequential = auc(fpr_Sequential, tpr_Sequential)
roc_auc_SVM = auc(fpr_SVM, tpr_SVM)
roc_auc_DT = auc(fpr_DT, tpr_DT)
roc_auc_KNN = auc(fpr_KNN, tpr_KNN)
roc_auc_GB = auc(fpr_GB, tpr_GB)



# Plotting
plt.figure(figsize=(15, 5))

# F1 Score
plt.subplot(1, 3, 1)
plt.bar(['Sequential', 'SVM','DT','KNN','GB'], [f1_Sequential,f1_SVM,f1_DT,f1_KNN,f1_GB], color=['blue', 'green','black','dimgray','forestgreen'])
plt.title('F1 Score')

# Precision-Recall Curve
plt.subplot(1, 3, 2)
plt.plot(precision_Sequential, recall_Sequential, color='blue', label=f'Sequential (AUC = {roc_auc_Sequential:.2f})')
plt.plot(precision_SVM, recall_SVM, color='green', label=f'SVM (AUC = {roc_auc_SVM:.2f})')
plt.plot(precision_DT, recall_DT, color='black', label=f'DT (AUC = {roc_auc_DT:.2f})')
plt.plot(precision_KNN, recall_KNN, color='dimgray', label=f'KNN (AUC = {roc_auc_KNN:.2f})')
plt.plot(precision_GB, recall_GB, color='forestgreen', label=f'GB (AUC = {roc_auc_GB:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend()


# ROC Curve
plt.subplot(1, 3, 3)
plt.plot(fpr_Sequential, tpr_Sequential, color='blue', label=f'Sequential (AUC = {roc_auc_Sequential:.2f})')
plt.plot(fpr_SVM, tpr_SVM, color='green', label=f'SVM(AUC = {roc_auc_SVM:.2f})')
plt.plot(fpr_DT, tpr_DT, color='black', label=f'DT (AUC = {roc_auc_DT:.2f})')
plt.plot(fpr_KNN, tpr_KNN, color='dimgray', label=f'KNN (AUC = {roc_auc_KNN:.2f})')
plt.plot(fpr_GB, tpr_GB, color='forestgreen', label=f'GB (AUC = {roc_auc_GB:.2f})')

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()

plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy as np

def calculate_sensitivity(y_true, y_pred):
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    sensitivity = tp / (tp + fn)
    return sensitivity
def calculate_specificity(y_true, y_pred):
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    specificity = tn / (tn + fp)
    return specificity
# Example data: Replace with your actual data
y_true =  np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,0,0,0,1,0,0])
y_scores_Sequential =  np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,0,0,0,1,1,1])
y_scores_SVM = np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,1,0,0,0,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,
 1,0,1,0,1,1,1,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,1,1,1,1,1,1])
y_scores_DT = np.array([1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,
 1,0,1,0,0,1,0,0,0,1,0,0])
y_scores_KNN =  np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,
 1,0,1,0,0,1,0,0,0,1,0,0])
y_scores_GB =  np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
 1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,
 1,1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,0,
 1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,
 1,0,1,0,0,1,1,1,1,1,1,0])

# Calculate sensitivity
sensitivity_Sequential = calculate_sensitivity(y_true, y_scores_Sequential)
sensitivity_SVM = calculate_sensitivity(y_true, y_scores_SVM)
sensitivity_DT = calculate_sensitivity(y_true, y_scores_DT)
sensitivity_KNN = calculate_sensitivity(y_true, y_scores_KNN)
sensitivity_GB = calculate_sensitivity(y_true, y_scores_GB)


calculate_specificity_Sequential = calculate_specificity(y_true, y_scores_Sequential)
calculate_specificity_SVM = calculate_specificity(y_true, y_scores_SVM)
calculate_specificity_DT = calculate_specificity(y_true, y_scores_DT)
calculate_specificity_KNN = calculate_specificity(y_true, y_scores_KNN)
calculate_specificity_GB = calculate_specificity(y_true, y_scores_GB)

print("calculate_specificity_Sequential:",calculate_specificity_Sequential)
print("calculate_specificity_SVM:",calculate_specificity_SVM)
print("calculate_specificity_DT:",calculate_specificity_DT)
print("calculate_specificity_KNN:",calculate_specificity_KNN)
print("calculate_specificity_GB:",calculate_specificity_GB)
center=0
# Sensitivity curve Curve
# plt.figure(figsize=(10,6 ))
# plt.subplot(1, 3, 2)
# plt.plot(sensitivity_Sequential,center, color='blue', label=f'Sequential {sensitivity_Sequential}', marker='o', linestyle='-')
# plt.plot(sensitivity_SVM, center,color='green', label=f'SVM {sensitivity_SVM}', marker='o', linestyle='-')
# plt.plot(sensitivity_DT, center,color='black', label=f'DT {sensitivity_DT}', marker='o', linestyle='-')
# plt.plot(sensitivity_KNN,center, color='dimgray', label=f'KNN {sensitivity_KNN}', marker='o', linestyle='-')
# plt.plot(sensitivity_GB ,center, color='forestgreen', label=f'GB {sensitivity_GB}', marker='o', linestyle='-')
# plt.xlabel('Ytrue')
# plt.ylabel('Ypred')
# plt.title('Sensitivity Curve')
# plt.legend()
# plt.tight_layout()
# plt.show()
models=[sensitivity_Sequential, sensitivity_SVM, sensitivity_DT,sensitivity_KNN,sensitivity_GB]
plt.bar(['Sequential', 'SVM','DT','KNN','GB'], [sensitivity_Sequential, sensitivity_SVM, sensitivity_DT,sensitivity_KNN,sensitivity_GB], color=['blue', 'green','black','dimgray','forestgreen'])
#plt.bar(models, [sensitivity_Sequential, sensitivity_SVM, sensitivity_DT,sensitivity_KNN,sensitivity_GB], color=['blue', 'green', 'orange','pink','black'])
plt.title('Sensitivity for Different Classifier')
plt.xlabel('Classifiers')
plt.ylabel('Sensitivity (True Positive Rate)')
plt.ylim(0, 1)  # Set y-axis limits (0 to 1 for sensitivity)
plt.legend()
plt.show()

import cv2
import matplotlib.pyplot as plt

# Load the image
image_path = 'path/to/your/image.jpg'
image = cv2.imread(image_path)

# Convert the image to grayscale (optional, depending on your requirements)
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Define the ROI coordinates (format: top-left corner (x, y), bottom-right corner (x, y))
roi_coordinates = ((100, 50), (300, 250))

# Extract the ROI from the image
roi = image[roi_coordinates[0][1]:roi_coordinates[1][1], roi_coordinates[0][0]:roi_coordinates[1][0]]

# Display the original image and the extracted ROI side by side
plt.subplot(1, 2, 1)
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title('Original Image')

plt.subplot(1, 2, 2)
plt.imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))
plt.title('Extracted ROI')

plt.show()